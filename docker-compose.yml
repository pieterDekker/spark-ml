version: "3.8"

x-spark-common: &spark-common
  build:
    context: ./spark
    dockerfile: Dockerfile
  volumes:
    - ./spark/apps:/opt/spark-apps
    - ./spark/data:/opt/spark-data

services:
  spark-master:
    <<: *spark-common
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
  #------
  spark-worker-a:
    <<: *spark-common
    ports:
      - "8081:8080"
      - "7011:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
  #------
  spark-worker-b:
    <<: *spark-common
    ports:
      - "8082:8080"
      - "7012:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
  #------
  demo-database:
    image: postgres:11.7-alpine
    volumes:
      - ./demo-database/data:/var/lib/postgresql/data
    ports: 
      - "5432:5432"
    environment:
      - POSTGRES_PASSWORD=casa1234
  #------
  kafka_box:
    image: lensesio/fast-data-dev
    volumes:
      - ./kafka-connect/data:/var/data
    deploy:
      resources:
        limits:
          cpus: '0.50'
    ports:
      - 3030:3030
      - 9092:9092
  #------
  python-box:
    image: python:3.11-alpine
    volumes:
      - ./python-box:/opt/python-box
    entrypoint: ["tail", "-f", "/dev/null"]

