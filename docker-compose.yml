version: "3.8"

x-spark-common: &spark-common
  build:
    context: ./spark
    dockerfile: Dockerfile
    args:
      SPARK_VERSION: 3.5.0
      HADOOP_VERSION: 3
  volumes:
    - ./spark/apps:/opt/spark-apps
    - ./spark/data:/opt/spark-data

services:
  spark-master:
    <<: *spark-common
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
  #------
  spark-worker-a:
    <<: *spark-common
    ports:
      - "8081:8080"
      - "7011:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
  #------
  spark-worker-b:
    <<: *spark-common
    ports:
      - "8082:8080"
      - "7012:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
  #------
  demo-database:
    image: postgres:11.7-alpine
    volumes:
      - ./demo-database/data:/var/lib/postgresql/data
    ports: 
      - "5432:5432"
    environment:
      - POSTGRES_PASSWORD=casa1234
  #------
  kafka-box:
    image: lensesio/fast-data-dev
    volumes:
      - ./kafka-connect/data:/var/data
    deploy:
      resources:
        limits:
          cpus: '0.50'
    ports:
      - 3030:3030
      - 9092:9092
  #------
  python-box:
    image: python:3.11-alpine
    volumes:
      - ./python-box:/opt/python-box
    entrypoint: ["tail", "-f", "/dev/null"]
  #------
  cassandra:
    image: cassandra:3.11
    volumes:
      - cassandra-volume:/var/lib/cassandra
    ports:
      - 9042:9042
  cassandra-init:
    image: cassandra:3.11
    volumes:
      - ./spark/data/transactions-dataset-for-cassandra.csv:/data/transactions-dataset.csv
      - ./spark/data/limit20-for-cassandra.csv:/data/limit20.csv
      - ./cassandra/init.cql:/opt/cassandra-init/init.cql
      - ./cassandra/init.sh:/opt/cassandra-init/init.sh
    entrypoint: ["bash"]
    command: "/opt/cassandra-init/init.sh"
  #------

volumes:
  cassandra-volume:
